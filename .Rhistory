library(usethis)
library(roxygen2)
library(devtools)
use_r("hello")
document()
build()
check()
check()
use_r("expand_queries")
open("R/expand_queries.R")
View("R/expand_queries.R")
document()
build()
check()
use_mit_license( copyright_holder = "Rie Matsumoto" )
use_description(
Title = "A Toolkit for Bibliometric Analysis",
Description = "A package for bibliometric analysis and data visualisation",
Author = "Rie Matsumoto",
Maintainer = "Rie Matsumoto <rie.hayashi.22@ucl.ac.uk>"
)
use_description(
Title = "A Toolkit for Bibliometric Analysis",
Description = "A package for bibliometric analysis and data visualisation",
Author = "Rie Matsumoto",
Maintainer = "Rie Matsumoto <rie.hayashi.22@ucl.ac.uk>"
)
use_description( fields = list(
Title = "A Toolkit for Bibliometric Analysis",
Description = "A package for bibliometric analysis and data visualisation",
Author = "Rie Matsumoto",
Maintainer = "Rie Matsumoto <rie.hayashi.22@ucl.ac.uk>"
))
document()
build()
check()
document()
use_version( "patch" )
build()
check()
library(rscopus)
rscopus::is_elsevier_authorized()
rscopus::have_api_key()
NAIVE_TERMS = c("quantum computer", "supply chain")
naive_query = paste0( "TITLE-ABS-KEY (", NAIVE_TERMS, ")" )
naive_query
naive_query = paste0( "TITLE-ABS-KEY (", paste0( NAIVE_TERMS ), ")" )
naive_query
paste0( NAIVE_TERMS)
?paste0
paste0( NAIVE_TERMS, sep=" " )
paste0( NAIVE_TERMS, collapse = " " )
paste0( NAIVE_TERMS, collapse = " AND " )
paste0('"', NAIVE_TERMS, '"', collapse = ' AND ')
paste0( "TITLE-ABS-KEY (", paste0('"', NAIVE_TERMS, '"', collapse = ' AND '), ")" )
res <- rscopus::scopus_search(
query = QUERY,
view = "COMPLETE", # to include all authors, COMPLETE view is needed
count = 25,        # to use COMPLETE view, count should be below 25
max_count = 25
)
QUERY = paste0( "TITLE-ABS-KEY (", paste0('"', NAIVE_TERMS, '"', collapse = ' AND '), ")" )
CTIME = format( Sys.time(), "%Y%m%d_%H%M" )
res <- rscopus::scopus_search(
query = QUERY,
view = "COMPLETE", # to include all authors, COMPLETE view is needed
count = 25,        # to use COMPLETE view, count should be below 25
max_count = 25
)
res
res$entries
entries = res$entries
library(litsearchr)
packageVersion("litsearchr")
entries
entries[[1]]
View(entries)
entries[[,]]$authkeywords
entries[[1:25]]$authkeywords
entries$authkeywords
lapply( entries, function(x) x$authkeywords )
entries[[1]]$authkeywords
char(entries[[1]]$authkeywords)
character(entries[[1]]$authkeywords)
sapply( entries, function(x) x$authkeywords )
sapply( entries, function(x) x$authkeywords, simplify = TRUE )
lapply( entries, function(x) x$authkeywords, simplify = TRUE )
lapply( entries, function(x) x$authkeywords )
unlist( lapply( entries, function(x) x$authkeywords ) )
library(litsearchr)
litsearchr::extract_terms(
keywords = unlist( lapply( entries, function(x) x$authkeywords ) ),
method = "tagged",
min_freq = 3,
min_n = 2,
stopwords = all_stopwords
)
all_stopwords <- c( get_stopwords( "English" ), read_lines( "my_stopwords" ) )
all_stopwords <- c( litsearchr::get_stopwords( "English" ), readr::read_lines( "my_stopwords" ) )
litsearchr::extract_terms(
keywords = unlist( lapply( entries, function(x) x$authkeywords ) ),
method = "tagged",
min_freq = 3,
min_n = 2,
stopwords = all_stopwords
)
litsearchr::extract_terms(
keywords = unlist( lapply( entries, function(x) x$authkeywords ) ),
method = "tagged",
min_freq = 1,
min_n = 1,
stopwords = all_stopwords
)
naive_keywords = unlist( lapply( entries, function(x) x$authkeywords ) )
naive_keywords
?extract_terms
res <- rscopus::scopus_search(
query = QUERY,
view = "COMPLETE", # to include all authors, COMPLETE view is needed
count = 25,        # to use COMPLETE view, count should be below 25
max_count = 200
)
entries = res$entries
all_stopwords <- c( litsearchr::get_stopwords( "English" ), readr::read_lines( "my_stopwords" ) )
naive_keywords = unlist( lapply( entries, function(x) x$authkeywords ) )
litsearchr::extract_terms(
keywords = naive_keywords,
method = "tagged",
min_freq = 1,
min_n = 1,
stopwords = all_stopwords
)
naive_keywords <-
lapply( entries, function(x) x$authkeywords ) |>
unlist() |>
gsub("\\|", "and", text)
naive_keywords <- unlist( lapply( entries, function(x) x$authkeywords ) ) |>
gsub("\\|", "and", text)
naive_keywords <- unlist( lapply( entries, function(x) x$authkeywords ) ) |>
gsub("\\|", "and")
naive_keywords <- unlist( lapply( entries, function(x) x$authkeywords ) ) |>
naive_keywords <- gsub( "\\|", "and", naive_keywords )
naive_keywords <- unlist( lapply( entries, function(x) x$authkeywords ) )
naive_keywords <- gsub( "\\|", "and", naive_keywords )
naive_keywords
litsearchr::extract_terms(
keywords = naive_keywords,
method = "tagged",
min_freq = 1,
min_n = 1,
stopwords = all_stopwords
)
litsearchr::extract_terms(
keywords = naive_keywords,
method = "tagged",
min_freq = 3,
min_n = 1,
stopwords = all_stopwords
)
litsearchr::extract_terms(
keywords = naive_keywords,
method = "tagged",
min_freq = 2,
min_n = 1,
stopwords = all_stopwords
)
entries[[1]]$`dc:title`
# title extraction
naive_titles <- unlist( lapply( entries, function(x) x$`dc:title` ) )
naive_titles
keywords <- litsearchr::extract_terms(
keywords = naive_keywords,
method = "tagged",
min_freq = 2,
min_n = 1,
stopwords = all_stopwords
)
title_terms <- litsearchr::extract_terms (
text = naive_titles,
method = "fakerake",
min_freq = 3,
min_n = 2,
stopwords = all_stopwords
)
title_terms
title_terms <- litsearchr::extract_terms (
text = naive_titles,
method = "fakerake",
min_freq = 2,
min_n = 1,
stopwords = all_stopwords
)
title_terms
terms <- unique( c( keywords, title_terms ) )
entries[[1]]$`dc:description`
# network analysis
naive_abstracts <- unlist( lapply( entries, function(x) x$`dc:description` ) )
naive_abstracts
docs <- paste( naive_titles, naive_abstracts )
docs
dfm <- create_dfm( elements = docs, features = terms )
?create_dfm
dfm <- litsearchr::create_dfm( elements = docs, features = terms )
dfm
g <- litsearchr::create_network( dfm, min_studies = 10 )
g
ggraph( g, layout = "stress" ) +
coord_fixed() +
expand_limits( x = c( -3, 3 ) ) +
geom_edge_link( aes( alpha = weight ) ) +
geom_node_point( shape = "circle filled", fill = "white" ) +
geom_node_text( aes( label = name ), hjust = "outward", check_overlap = TRUE ) +
guides( edge_alpha = FALSE )
library(ggraph)
ggraph( g, layout = "stress" ) +
coord_fixed() +
expand_limits( x = c( -3, 3 ) ) +
geom_edge_link( aes( alpha = weight ) ) +
geom_node_point( shape = "circle filled", fill = "white" ) +
geom_node_text( aes( label = name ), hjust = "outward", check_overlap = TRUE ) +
guides( edge_alpha = FALSE )
strengths <- strength( g )
strengths <- igraph::strength( g )
term_strengths <- data.frame(
term = names( strengths ),
strength = strengths,
row.names = NULL
) |>
mutate( rank = rank( strength, ties.method = "min" ) ) |>
arrange( strength )
term_strengths <- data.frame(
term = names( strengths ),
strength = strengths,
row.names = NULL
) |>
mutate( rank = rank( strength, ties.method = "min" ) ) |>
arrange( strength )
term_strengths <- data.frame(
term = names( strengths ),
strength = strengths,
row.names = NULL
) |>
mutate( rank = rank( strength, ties.method = "min" ) ) |>
dplyr::arrange( strength )
term_strengths <- data.frame(
term = names( strengths ),
strength = strengths,
row.names = NULL
) |>
dplyr::mutate( rank = rank( strength, ties.method = "min" ) ) |>
dplyr::arrange( strength )
cutoff_cum <- litsearchr::find_cutoff( g, method = "cumulative", percent = 0.8 )
litsearchr::get_keywords( litsearchr::reduce_graph( g, cutoff_cum ) )
selected_terms <- litsearchr::get_keywords( litsearchr::reduce_graph( g, cutoff_cum ) )
selected_terms
expanded_query <- paste0( "TITLE-ABS-KEY (", paste0('"', selected_terms, '"', collapse = ' AND '), ")" )
expanded_query
document()
document()
document()
document()
use_version( "patch" )
build()
check()
check()
build()
build()
check()
MY_STOPWORDS_PATH <- system.file("extdata", "my_stopwords", package = "bibliokit")
all_stopwords <- c( litsearchr::get_stopwords( "English" ), readr::read_lines( MY_STOPWORDS_PATH ) )
readr::read_lines( MY_STOPWORDS_PATH)
build()
check()
build()
check()
expanded_query <- paste0( "TITLE-ABS-KEY (", paste0('"', selected_terms, '"', collapse = ' AND '), ")" )
expanded_query
QUERY = paste0( "TITLE-ABS-KEY (", paste0('"', naive_terms, '"', collapse = ' AND '), ")" )
naive_terms = "quantum computing"
QUERY = paste0( "TITLE-ABS-KEY (", paste0('"', naive_terms, '"', collapse = ' AND '), ")" )
CTIME = format( Sys.time(), "%Y%m%d_%H%M" )
res <- rscopus::scopus_search(
query = QUERY,
view = "COMPLETE", # to include all authors, COMPLETE view is needed
count = 25,        # to use COMPLETE view, count should be below 25
max_count = 25
)
entries = res$entries
my_stopwords_path <- system.file( "extdata", "my_stopwords", package = "bibliokit" )
all_stopwords <- c( litsearchr::get_stopwords( "English" ), readr::read_lines( my_stopwords_path ) )
# keyword extraction
naive_keywords <- unlist( lapply( entries, function(x) x$authkeywords ) )
naive_keywords <- gsub( "\\|", "and", naive_keywords )
keywords <- litsearchr::extract_terms(
keywords = naive_keywords,
method = "tagged",
min_freq = 2,
min_n = 1,
stopwords = all_stopwords
)
keywords <- litsearchr::extract_terms(
keywords = naive_keywords,
method = "tagged",
min_freq = 1,
min_n = 1,
stopwords = all_stopwords
)
keywords
# title extraction
naive_titles <- unlist( lapply( entries, function(x) x$`dc:title` ) )
title_terms <- litsearchr::extract_terms (
text = naive_titles,
method = "fakerake",
min_freq = 2,
min_n = 1,
stopwords = all_stopwords
)
title_terms
title_terms <- litsearchr::extract_terms (
text = naive_titles,
method = "fakerake",
min_freq = 1,
min_n = 1,
stopwords = all_stopwords
)
title_terms
title_terms <- litsearchr::extract_terms (
text = naive_titles,
method = "fakerake",
min_freq = 2,
min_n = 1,
stopwords = all_stopwords
)
keywords <- litsearchr::extract_terms(
keywords = naive_keywords,
method = "tagged",
min_freq = 1,
min_n = 1,
stopwords = all_stopwords
)
keywords
keywords <- litsearchr::extract_terms(
keywords = naive_keywords,
method = "tagged",
min_freq = 2,
min_n = 1,
stopwords = all_stopwords
)
keywords
keywords <- litsearchr::extract_terms(
keywords = naive_keywords,
method = "tagged",
min_freq = 1,
min_n = 1,
stopwords = all_stopwords
)
title_terms <- litsearchr::extract_terms (
text = naive_titles,
method = "fakerake",
min_freq = 2,
min_n = 1,
stopwords = all_stopwords
)
title_terms
# keyword extraction
naive_keywords <- unlist( lapply( entries, function(x) x$authkeywords ) )
naive_keywords <- gsub( "\\|", "and", naive_keywords )
keywords <- litsearchr::extract_terms(
keywords = naive_keywords,
method = "tagged",
min_freq = 1,
min_n = 1,
stopwords = all_stopwords
)
# title extraction
naive_titles <- unlist( lapply( entries, function(x) x$`dc:title` ) )
title_terms <- litsearchr::extract_terms (
text = naive_titles,
method = "fakerake",
min_freq = 1,
min_n = 1,
stopwords = all_stopwords
)
terms <- unique( c( keywords, title_terms ) )
terms
# network analysis
naive_abstracts <- unlist( lapply( entries, function(x) x$`dc:description` ) )
docs <- paste( naive_titles, naive_abstracts )
dfm <- litsearchr::create_dfm( elements = docs, features = terms )
g <- litsearchr::create_network( dfm, min_studies = 10 )
cutoff_cum <- litsearchr::find_cutoff( g, method = "cumulative", percent = 0.8 )
selected_terms <- litsearchr::get_keywords( litsearchr::reduce_graph( g, cutoff_cum ) )
expanded_query <- paste0( "TITLE-ABS-KEY (", paste0('"', selected_terms, '"', collapse = ' AND '), ")" )
expanded_query
ggraph( g, layout = "stress" ) +
coord_fixed() +
expand_limits( x = c( -3, 3 ) ) +
geom_edge_link( aes( alpha = weight ) ) +
geom_node_point( shape = "circle filled", fill = "white" ) +
geom_node_text( aes( label = name ), hjust = "outward", check_overlap = TRUE ) +
guides( edge_alpha = FALSE )
g <- litsearchr::create_network( dfm, min_studies = 5 )
ggraph( g, layout = "stress" ) +
coord_fixed() +
expand_limits( x = c( -3, 3 ) ) +
geom_edge_link( aes( alpha = weight ) ) +
geom_node_point( shape = "circle filled", fill = "white" ) +
geom_node_text( aes( label = name ), hjust = "outward", check_overlap = TRUE ) +
guides( edge_alpha = FALSE )
cutoff_cum <- litsearchr::find_cutoff( g, method = "cumulative", percent = 0.8 )
selected_terms <- litsearchr::get_keywords( litsearchr::reduce_graph( g, cutoff_cum ) )
expanded_query <- paste0( "TITLE-ABS-KEY (", paste0('"', selected_terms, '"', collapse = ' AND '), ")" )
expanded_query
build()
