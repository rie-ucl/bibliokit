strengths <- igraph::strength(g)
term_strengths <- data.frame( term = names( strengths ), strength = strengths, row.names=NULL) |>
dplyr::mutate( rank = rank( strength, ties.method = "min" ) ) |>
dplyr::arrange( strength )
term_strengths
cutoff_cum <- litsearchr::find_cutoff( g, method = "cumulative", percent = 0.8 )
selected_terms <- litsearchr::get_keywords( litsearchr::reduce_graph( g, cutoff_cum ) )
return( selected_terms )
}
my_stopwords_path <- system.file( "extdata", "my_stopwords",
package = "bibliokit" )
my_stopwords_path
naive_terms = "technology transfer"
QUERY = paste0( "TITLE-ABS-KEY (",
paste0('"', naive_terms, '"', collapse = ' AND '),
")" )
res <- rscopus::scopus_search(
query = QUERY,
view = "COMPLETE", # to include all authors, COMPLETE view is needed
count = 25,        # to use COMPLETE view, count should be below 25
max_count = 200
)
my_stopwords_path <- system.file( "extdata", "my_stopwords",
package = "bibliokit" )
all_stopwords <- c( litsearchr::get_stopwords( "English" ),
readr::read_lines( my_stopwords_path ) )
# keyword extraction
naive_keywords <- unlist( lapply( entries, function(x) x$authkeywords ) )
entries = res$entries
# keyword extraction
naive_keywords <- unlist( lapply( entries, function(x) x$authkeywords ) )
naive_keywords <- gsub( "\\|", "and", naive_keywords )
keywords <- litsearchr::extract_terms(
keywords = naive_keywords,
method = "tagged",
min_freq = 3,
min_n = 2,
stopwords = all_stopwords
)
# title extraction
naive_titles <- unlist( lapply( entries, function(x) x$`dc:title` ) )
title_terms <- litsearchr::extract_terms (
text = naive_titles,
method = "fakerake",
min_freq = 3,
min_n = 2,
stopwords = all_stopwords
)
naive_abstracts <- unlist( lapply( entries, function(x) x$`dc:description` ) )
abst_terms <- litsearchr::extract_terms(
text = naive_abstracts,
method = "fakerake",
min_freq = 3,
min_n = 2,
stopwords = all_stopwords
)
# integration
terms <- unique( c( keywords, title_terms, abst_terms ) )
# network analysis
# naive_abstracts <- unlist( lapply( entries, function(x) x$`dc:description` ) )
docs <- paste( naive_titles, naive_abstracts )
dfm <- litsearchr::create_dfm( elements = docs, features = terms )
g <- litsearchr::create_network( dfm, min_studies = 5 )
strengths <- igraph::strength(g)
term_strengths <- data.frame( term = names( strengths ), strength = strengths, row.names=NULL) |>
dplyr::mutate( rank = rank( strength, ties.method = "min" ) ) |>
dplyr::arrange( strength )
term_strengths
cutoff_cum <- litsearchr::find_cutoff( g, method = "cumulative", percent = 0.8 )
selected_terms <- litsearchr::get_keywords( litsearchr::reduce_graph( g, cutoff_cum ) )
return( selected_terms )
selected_terms
term_strengths |>
ggplot( aes(x=rank, y=strength, label=term)) +
geom_line() +
geom_point() +
geom_text(data=filter(term_strengths, rank>5), hjust="right", nudge_y=20, check_overlap=TRUE)
term_strengths |>
ggplot2::ggplot( aes( x = rank, y = strength, label = term ) ) +
geom_line() +
geom_point() +
geom_text( data = filter( term_strengths, rank > 5 ),
hjust = "right", nudge_y = 20, check_overlap = TRUE)
term_strengths |>
ggplot2::ggplot( ggplot2::aes( x = rank, y = strength, label = term ) ) +
ggplot2::geom_line() +
ggplot2::geom_point() +
ggplot2::geom_text( data = filter( term_strengths, rank > 5 ),
hjust = "right", nudge_y = 20, check_overlap = TRUE)
term_strengths |>
ggplot2::ggplot( ggplot2::aes( x = rank, y = strength, label = term ) ) +
ggplot2::geom_line() +
ggplot2::geom_point() +
ggplot2::geom_text( data = filter( term_strengths, rank > 5 ),
hjust = "right", nudge_y = 20, check_overlap = TRUE)
term_strengths |>
ggplot2::ggplot( ggplot2::aes( x = rank, y = strength, label = term ) ) +
ggplot2::geom_line() +
ggplot2::geom_point() +
ggplot2::geom_text( data = dplyr::filter( term_strengths, rank > 5 ),
hjust = "right", nudge_y = 20, check_overlap = TRUE)
selected_terms <- litsearchr::get_keywords( litsearchr::reduce_graph( g, cutoff_cum ) )
file.remove( "NAMESPACE" )
source( "inst/scripts/generate_readme.R" )
document()
build()
install.packages("../bibliokit_0.1.0.tar.gz")
detach( "package:bibliokit", unload = TRUE )
install.packages("../bibliokit_0.1.0.tar.gz")
library( bibliokit )
library( bibliokit )
expand_search_terms("tech transfer")
expand_search_terms("technology transfer")
expand_search_terms("technology acquisition")
expand_search_terms(c( "technology", "transfer", "nation" ))
#' Expand Search Terms
#'
#' The `expand_search_terms()` function takes one or more initial search terms and
#' returns a query (expanded set of terms) by including related or similar terms.
#' The expansion helps to capture more relevant results by broadening the search.
#'
#' @param naive_terms A character vector of one or more initial search queries.
#' @return A character vector containing the original queries along with expanded search terms.
#' @examples
#' expand_search_terms( c( "data analysis", "machine learning" ) )
#'
#' @import utils
#' @import igraph
#' @import dplyr
#'
#' @export
expand_search_terms <- function( naive_terms ) {
QUERY = paste0( "TITLE-ABS-KEY (",
paste0('"', naive_terms, '"', collapse = ' AND '),
")" )
res <- rscopus::scopus_search(
query = QUERY,
view = "COMPLETE", # to include all authors, COMPLETE view is needed
count = 25,        # to use COMPLETE view, count should be below 25
max_count = 200
)
entries = res$entries
my_stopwords_path <- system.file( "extdata", "my_stopwords",
package = "bibliokit" )
all_stopwords <- c( litsearchr::get_stopwords( "English" ),
readr::read_lines( my_stopwords_path ) )
# keyword extraction
naive_keywords <- unlist( lapply( entries, function(x) x$authkeywords ) )
naive_keywords <- gsub( "\\|", "and", naive_keywords )
keywords <- litsearchr::extract_terms(
keywords = naive_keywords,
method = "tagged",
min_n = 1,
stopwords = all_stopwords
)
# title extraction
naive_titles <- unlist( lapply( entries, function(x) x$`dc:title` ) )
title_terms <- litsearchr::extract_terms (
text = naive_titles,
method = "fakerake",
min_freq = 3,
min_n = 2,
stopwords = all_stopwords
)
naive_abstracts <- unlist( lapply( entries, function(x) x$`dc:description` ) )
abst_terms <- litsearchr::extract_terms(
text = naive_abstracts,
method = "fakerake",
min_freq = 3,
min_n = 2,
stopwords = all_stopwords
)
# integration
terms <- unique( c( keywords, title_terms, abst_terms ) )
# network analysis
# naive_abstracts <- unlist( lapply( entries, function(x) x$`dc:description` ) )
docs <- paste( naive_titles, naive_abstracts )
dfm <- litsearchr::create_dfm( elements = docs, features = terms )
g <- litsearchr::create_network( dfm, min_studies = 5 )
strengths <- igraph::strength(g)
term_strengths <- data.frame( term = names( strengths ), strength = strengths, row.names=NULL) |>
dplyr::mutate( rank = rank( strength, ties.method = "min" ) ) |>
dplyr::arrange( strength )
term_strengths |>
ggplot2::ggplot( ggplot2::aes( x = rank, y = strength, label = term ) ) +
ggplot2::geom_line() +
ggplot2::geom_point() +
ggplot2::geom_text( data = dplyr::filter( term_strengths, rank > 5 ),
hjust = "right", nudge_y = 20, check_overlap = TRUE)
cutoff_cum <- litsearchr::find_cutoff( g, method = "cumulative", percent = 0.8 )
selected_terms <- litsearchr::get_keywords( litsearchr::reduce_graph( g, cutoff_cum ) )
return( selected_terms )
}
expand_search_terms(c( "technology", "transfer", "nation" ))
expand_search_terms(c( "technology transfer", "technology acquisition" ))
#' Expand Search Terms
#'
#' The `expand_search_terms()` function takes one or more initial search terms and
#' returns a query (expanded set of terms) by including related or similar terms.
#' The expansion helps to capture more relevant results by broadening the search.
#'
#' @param naive_terms A character vector of one or more initial search queries.
#' @return A character vector containing the original queries along with expanded search terms.
#' @examples
#' expand_search_terms( c( "data analysis", "machine learning" ) )
#'
#' @import utils
#' @import igraph
#' @import dplyr
#'
#' @export
expand_search_terms <- function( naive_terms ) {
QUERY = paste0( "TITLE-ABS-KEY (",
paste0('"', naive_terms, '"', collapse = ' AND '),
")" )
res <- rscopus::scopus_search(
query = QUERY,
view = "COMPLETE", # to include all authors, COMPLETE view is needed
count = 25,        # to use COMPLETE view, count should be below 25
max_count = 200
)
entries = res$entries
my_stopwords_path <- system.file( "extdata", "my_stopwords",
package = "bibliokit" )
all_stopwords <- c( litsearchr::get_stopwords( "English" ),
readr::read_lines( my_stopwords_path ) )
# keyword extraction
naive_keywords <- unlist( lapply( entries, function(x) x$authkeywords ) )
naive_keywords <- gsub( "\\|", "and", naive_keywords )
keywords <- litsearchr::extract_terms(
keywords = naive_keywords,
method = "tagged",
min_n = 1,
min_freq = 3,
stopwords = all_stopwords
)
# title extraction
naive_titles <- unlist( lapply( entries, function(x) x$`dc:title` ) )
title_terms <- litsearchr::extract_terms (
text = naive_titles,
method = "fakerake",
min_freq = 3,
min_n = 2,
stopwords = all_stopwords
)
naive_abstracts <- unlist( lapply( entries, function(x) x$`dc:description` ) )
abst_terms <- litsearchr::extract_terms(
text = naive_abstracts,
method = "fakerake",
min_freq = 3,
min_n = 2,
stopwords = all_stopwords
)
# integration
terms <- unique( c( keywords, title_terms, abst_terms ) )
# network analysis
# naive_abstracts <- unlist( lapply( entries, function(x) x$`dc:description` ) )
docs <- paste( naive_titles, naive_abstracts )
dfm <- litsearchr::create_dfm( elements = docs, features = terms )
g <- litsearchr::create_network( dfm, min_studies = 5 )
strengths <- igraph::strength(g)
term_strengths <- data.frame( term = names( strengths ), strength = strengths, row.names=NULL) |>
dplyr::mutate( rank = rank( strength, ties.method = "min" ) ) |>
dplyr::arrange( strength )
term_strengths |>
ggplot2::ggplot( ggplot2::aes( x = rank, y = strength, label = term ) ) +
ggplot2::geom_line() +
ggplot2::geom_point() +
ggplot2::geom_text( data = dplyr::filter( term_strengths, rank > 5 ),
hjust = "right", nudge_y = 20, check_overlap = TRUE)
cutoff_cum <- litsearchr::find_cutoff( g, method = "cumulative", percent = 0.8 )
selected_terms <- litsearchr::get_keywords( litsearchr::reduce_graph( g, cutoff_cum ) )
return( selected_terms )
}
expand_search_terms(c( "technology transfer", "technology acquisition" ))
build()
detach( "package:bibliokit", unload = TRUE )
install.packages("../bibliokit_0.1.0.tar.gz")
library( bibliokit )
library( bibliokit )
expand_search_terms(c( "technology transfer", "technology acquisition" ))
"acquisitions"                    "case study"                      "china"
#' Expand Search Terms
#'
#' The `expand_search_terms()` function takes one or more initial search terms and
#' returns a query (expanded set of terms) by including related or similar terms.
#' The expansion helps to capture more relevant results by broadening the search.
#'
#' @param naive_terms A character vector of one or more initial search queries.
#' @return A character vector containing the original queries along with expanded search terms.
#' @examples
#' expand_search_terms( c( "data analysis", "machine learning" ) )
#'
#' @import utils
#' @import igraph
#' @import dplyr
#'
#' @export
expand_search_terms <- function( naive_terms ) {
QUERY = paste0( "TITLE-ABS-KEY (",
paste0('"', naive_terms, '"', collapse = ' AND '),
")" )
res <- rscopus::scopus_search(
query = QUERY,
view = "COMPLETE", # to include all authors, COMPLETE view is needed
count = 25,        # to use COMPLETE view, count should be below 25
max_count = 200
)
entries = res$entries
my_stopwords_path <- system.file( "extdata", "my_stopwords",
package = "bibliokit" )
all_stopwords <- c( litsearchr::get_stopwords( "English" ),
readr::read_lines( my_stopwords_path ) )
# keyword extraction
naive_keywords <- unlist( lapply( entries, function(x) x$authkeywords ) )
naive_keywords <- gsub( "\\|", "and", naive_keywords )
keywords <- litsearchr::extract_terms(
keywords = naive_keywords,
method = "tagged",
min_n = 1,
min_freq = 3,
stopwords = all_stopwords
)
# title extraction
naive_titles <- unlist( lapply( entries, function(x) x$`dc:title` ) )
title_terms <- litsearchr::extract_terms (
text = naive_titles,
method = "fakerake",
min_freq = 3,
min_n = 2,
stopwords = all_stopwords
)
naive_abstracts <- unlist( lapply( entries, function(x) x$`dc:description` ) )
abst_terms <- litsearchr::extract_terms(
text = naive_abstracts,
method = "fakerake",
min_freq = 3,
min_n = 2,
stopwords = all_stopwords
)
# integration
terms <- unique( c( keywords, title_terms, abst_terms ) )
# network analysis
# naive_abstracts <- unlist( lapply( entries, function(x) x$`dc:description` ) )
docs <- paste( naive_titles, naive_abstracts )
dfm <- litsearchr::create_dfm( elements = docs, features = terms )
g <- litsearchr::create_network( dfm, min_studies = 5 )
strengths <- igraph::strength(g)
term_strengths <- data.frame( term = names( strengths ), strength = strengths, row.names=NULL) |>
dplyr::mutate( rank = rank( strength, ties.method = "min" ) ) |>
dplyr::arrange( strength )
term_strengths |>
ggplot2::ggplot( ggplot2::aes( x = rank, y = strength, label = term ) ) +
ggplot2::geom_line() +
ggplot2::geom_point() +
ggplot2::geom_text( data = dplyr::filter( term_strengths, rank > 5 ),
hjust = "right", nudge_y = 20, check_overlap = TRUE)
cutoff_cum <- litsearchr::find_cutoff( g, method = "cumulative", percent = 0.8 )
selected_terms <- litsearchr::get_keywords( litsearchr::reduce_graph( g, cutoff_cum ) )
return( selected_terms )
}
QUERY <- ifelse( length(naive_terms) > 1 ,
paste0( "TITLE-ABS-KEY (",
paste0('"', naive_terms, '"', collapse = ' AND '),
")" ),
naive_terms
)
naive_terms <- "hoge"
QUERY <- ifelse( length(naive_terms) > 1 ,
paste0( "TITLE-ABS-KEY (",
paste0('"', naive_terms, '"', collapse = ' AND '),
")" ),
naive_terms
)
naive_terms <- c("hoge", "hoge2")
QUERY <- ifelse( length(naive_terms) > 1 ,
paste0( "TITLE-ABS-KEY (",
paste0('"', naive_terms, '"', collapse = ' AND '),
")" ),
naive_terms
)
QUERY <-
paste0( "TITLE-ABS-KEY (",
ifelse( length(naive_terms) > 1 ,
paste0('"', naive_terms, '"', collapse = ' AND '),
naive_terms
),
")" )
#' Expand Search Terms
#'
#' The `expand_search_terms()` function takes one or more initial search terms and
#' returns a query (expanded set of terms) by including related or similar terms.
#' The expansion helps to capture more relevant results by broadening the search.
#'
#' @param naive_terms A character vector of one or more initial search queries.
#' @return A character vector containing the original queries along with expanded search terms.
#' @examples
#' expand_search_terms( c( "data analysis", "machine learning" ) )
#'
#' @import utils
#' @import igraph
#' @import dplyr
#'
#' @export
expand_search_terms <- function( naive_terms ) {
QUERY <-
paste0( "TITLE-ABS-KEY (",
ifelse( length(naive_terms) > 1 ,
paste0('"', naive_terms, '"', collapse = ' AND '),
naive_terms
),
")" )
res <- rscopus::scopus_search(
query = QUERY,
view = "COMPLETE", # to include all authors, COMPLETE view is needed
count = 25,        # to use COMPLETE view, count should be below 25
max_count = 200
)
entries = res$entries
my_stopwords_path <- system.file( "extdata", "my_stopwords",
package = "bibliokit" )
all_stopwords <- c( litsearchr::get_stopwords( "English" ),
readr::read_lines( my_stopwords_path ) )
# keyword extraction
naive_keywords <- unlist( lapply( entries, function(x) x$authkeywords ) )
naive_keywords <- gsub( "\\|", "and", naive_keywords )
keywords <- litsearchr::extract_terms(
keywords = naive_keywords,
method = "tagged",
min_n = 1,
min_freq = 3,
stopwords = all_stopwords
)
# title extraction
naive_titles <- unlist( lapply( entries, function(x) x$`dc:title` ) )
title_terms <- litsearchr::extract_terms (
text = naive_titles,
method = "fakerake",
min_freq = 3,
min_n = 2,
stopwords = all_stopwords
)
naive_abstracts <- unlist( lapply( entries, function(x) x$`dc:description` ) )
abst_terms <- litsearchr::extract_terms(
text = naive_abstracts,
method = "fakerake",
min_freq = 3,
min_n = 2,
stopwords = all_stopwords
)
# integration
terms <- unique( c( keywords, title_terms, abst_terms ) )
# network analysis
# naive_abstracts <- unlist( lapply( entries, function(x) x$`dc:description` ) )
docs <- paste( naive_titles, naive_abstracts )
dfm <- litsearchr::create_dfm( elements = docs, features = terms )
g <- litsearchr::create_network( dfm, min_studies = 5 )
strengths <- igraph::strength(g)
term_strengths <- data.frame( term = names( strengths ), strength = strengths, row.names=NULL) |>
dplyr::mutate( rank = rank( strength, ties.method = "min" ) ) |>
dplyr::arrange( strength )
term_strengths |>
ggplot2::ggplot( ggplot2::aes( x = rank, y = strength, label = term ) ) +
ggplot2::geom_line() +
ggplot2::geom_point() +
ggplot2::geom_text( data = dplyr::filter( term_strengths, rank > 5 ),
hjust = "right", nudge_y = 20, check_overlap = TRUE)
cutoff_cum <- litsearchr::find_cutoff( g, method = "cumulative", percent = 0.8 )
selected_terms <- litsearchr::get_keywords( litsearchr::reduce_graph( g, cutoff_cum ) )
return( selected_terms )
}
expand_search_terms( c( "countries", "technology transfer", "innovation", "security" ) )
expand_search_terms( `"countries" AND "technology transfer" AND ( "development" OR "innovation" ) AND ( security OR "food security" OR "national security" )` )
expand_search_terms( "countries AND `technology transfer` AND ( development OR innovation ) AND security" )
expand_search_terms( "countries AND \"technology transfer\" AND ( development OR innovation ) AND security" )
setwd( "C:/Users/Rie/OneDrive - University College London/R/packages/bibliokit/" )
file.remove( "NAMESPACE" )
source( "inst/scripts/generate_readme.R" )
document()
library(usethis)
library(roxygen2)
library(devtools)
setwd( "C:/Users/Rie/OneDrive - University College London/R/packages/bibliokit/" )
file.remove( "NAMESPACE" )
source( "inst/scripts/generate_readme.R" )
document()
build()
check()
install.packages("../bibliokit_0.1.0.tar.gz")
library( bibliokit )
detach( "package:bibliokit", unload = TRUE )
library(usethis)
library(roxygen2)
library(devtools)
setwd( "C:/Users/Rie/OneDrive - University College London/R/packages/bibliokit/" )
file.remove( "NAMESPACE" )
source( "inst/scripts/generate_readme.R" )
document()
build()
detach( "package:bibliokit", unload = TRUE )
install.packages("../bibliokit_0.1.0.tar.gz")
document()
setwd( "C:/Users/Rie/OneDrive - University College London/R/packages/bibliokit/" )
file.remove( "NAMESPACE" )
detach( "package:bibliokit", unload = TRUE )
source( "inst/scripts/generate_readme.R" )
document()
build()
check()
detach( "package:bibliokit", unload = TRUE )
install.packages("../bibliokit_0.1.0.tar.gz")
library( bibliokit )
